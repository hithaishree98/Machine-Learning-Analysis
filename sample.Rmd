---
title: "Part_2_Regression"
output: html_document
date: "2024-04-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Load packages

This example uses the `tidyverse` suite of packages.  

```{r, load_tidyverse}
library(tidyverse)
library(corrplot)
library(coefplot)
library(splines)
library(rstanarm)
```

## Regression task

# ```{r, read_final_data}
# df <- readr::read_csv("paint_project_train_data.csv", col_names = TRUE)
# df %>% glimpse()
# ```

As stated in the project guidelines, you will **not** model the continuous output, `response`, directly. The `response` is a bounded variable between 0 and 100. The `response` must be transformed to an unbounded variable to appropriately be modeled by a Gaussian likelihood. We are making this transformation because we want the **uncertainty** in the predicted output to also satisfy output constraints. If we did not make this transformation the uncertainty could violate the bounds, which would mean the model is providing unphysical results! By logit-transforming `response`, we will fully respect the bounds of the output variable.  

The code chunk below assembles the data for Part ii) of the project. You should use this data set for all regression modeling tasks. The logit-transformed output is named `y`. The `dfii` dataframe as the original `response` and Binary output, `outcome`, removed. This way you can focus on the variables specific to the regression task.  


# ```{r, make_reg_data}
# dfii <- df %>% 
#   mutate(y = boot::logit( (response - 0) / (100 - 0) ) ) %>% 
#   select(R, G, B, 
#          Lightness, Saturation, Hue,
#          y)
# 
# dfii 
# ```


```{r}
df <- readr::read_csv("paint_project_train_data.csv", col_names = TRUE)
# Inspect the data structure
glimpse(df)

# Transform 'response' using the logit function
# Avoid division by zero or division by 100 by adjusting the boundaries slightly
dfii <- df %>%
  mutate(y = boot::logit((response - 0) / (100 - 0))) %>%
  select(R, G, B, Lightness, Saturation, Hue, y)

# Fit specified models
mod01 <- lm( y ~ 1, data = dfii )
mod02 <- lm( y ~ Lightness + Saturation, data = dfii)
mod03 <- lm(y ~ R + G + B + Hue, data = dfii)
mod04 <- lm(y ~ R + G + B + Lightness + Saturation + Hue, data = dfii)
# Display summaries of each model if needed (example for mod01)




mod01 <- stan_glm(y ~ 1, data = dfii, family = gaussian(), prior = normal(0, 2.5))
mod02 <- stan_glm(y ~ Lightness + Saturation, data = dfii, family = gaussian(), prior = normal(0, 2.5))
mod03 <- stan_glm(y ~ R + G + B + Hue, data = dfii, family = gaussian(), prior = normal(0, 2.5))
mod04 <- stan_glm(y ~ R + G + B + Lightness + Saturation + Hue, data = dfii, family = gaussian(), prior = normal(0, 2.5))
```


**Important**: It is up to you as to whether further preprocessing of the inputs are required before fitting the models.  

### Simple model

You are going to fit many models in this project. Rather than having a single large RMarkdown that fits all models, it can be useful to work in a modular fashion. You can have separate RMarkdowns for different portions of the project. You can fit/train models, save them, and then load them in other RMarkdowns as needed. This example RMarkdown shows how to fit a simple linear model just to show the process of saving and loading the model object back in.

I will not preprocess the inputs before fitting this model. Please note that you should consider if preprocessing would be useful or not! The code chunk below fits a linear model to predict the logit-transformed output `y` via a linear relationship to the `R` input. The result is assigned to the `mod01` object.  

<!-- ##Intercept-only model – no INPUTS! -->
<!-- • Categorical variables only – linear additive -->
<!-- • Continuous variables only – linear additive -->
<!-- • All categorical and continuous variables – linear additive -->
<!-- • Interaction of the categorical inputs with all continuous inputs main effects -->
<!-- • Add categorical inputs to all main effect and all pairwise interactions of continuous inputs -->
<!-- • Interaction of the categorical inputs with all main effect and all pairwise interactions of continuous inputs -->
<!-- 3 models with basis functions of your choice -->
<!-- • Try non-linear basis functions based on your EDA. -->
<!-- • Can consider interactions of basis functions with other basis functions! -->
<!-- • Can consider interactions of basis functions with the categorical inputs! -->



```{r}
mod01 <- lm( y ~ 1, data = dfii )
mod02 <- lm( y ~ Lightness + Saturation, data = dfii)
mod03 <- lm(y ~ R + G + B + Hue, data = dfii)
mod04 <- lm(y ~ R + G + B + Lightness + Saturation + Hue, data = dfii)
# mod05 <- lm(y ~ (Lightness + Saturation) * (R + G + B + Hue), data = dfii)
# mod06 <- lm(y ~ (Lightness + Saturation) * (R + G + B + Hue), data = dfii)
# mod07 <- lm(y ~ (Lightness + Saturation) * (R + G + B + Hue)^2, data = dfii)
# mod08 <- lm(y ~ poly(R, 3) + poly(G, 3) + poly(B, 3) + poly(Hue, 3), data = dfii)
# mod09 <- lm(y ~ (bs(R) + bs(G) + bs(B) + bs(Hue))^2, data = dfii)
# mod10 <- lm(y ~ (bs(R) + bs(G) + bs(B) + bs(Hue)) * (Lightness + Saturation), data = dfii)
```


```{r}
# mod01 %>% summary()
# mod02 %>% summary()
# mod03 %>% summary()
# mod04 %>% summary()
# mod05 %>% summary()
 mod06 %>% summary()
# mod07 %>% summary()
# mod08 %>% summary()
# mod09 %>% summary()
# mod10 %>% summary()
```


```{r, save_mod01}
# mod01 %>% readr::write_rds("my_mod01.rds")
# mod02 %>% readr::write_rds("my_mod02.rds")
# mod03 %>% readr::write_rds("my_mod03.rds")
# mod04 %>% readr::write_rds("my_mod04.rds")
# mod05 %>% readr::write_rds("my_mod05.rds")
# mod06 %>% readr::write_rds("my_mod06.rds")
# mod07 %>% readr::write_rds("my_mod07.rds")
# mod08 %>% readr::write_rds("my_mod08.rds")
# mod09 %>% readr::write_rds("my_mod09.rds")
# mod10 %>% readr::write_rds("my_mod10.rds")
```

```{r, reload_mod01}
# re_load_mod01 <- readr::read_rds("my_mod01.rds")
# re_load_mod02 <- readr::read_rds("my_mod02.rds")
# re_load_mod03 <- readr::read_rds("my_mod03.rds")
# re_load_mod04 <- readr::read_rds("my_mod04.rds")
# re_load_mod05 <- readr::read_rds("my_mod05.rds")
# re_load_mod06 <- readr::read_rds("my_mod06.rds")
# re_load_mod07 <- readr::read_rds("my_mod07.rds")
# re_load_mod08 <- readr::read_rds("my_mod08.rds")
# re_load_mod09 <- readr::read_rds("my_mod09.rds")
# re_load_mod10 <- readr::read_rds("my_mod10.rds")
```

```{r, check_reload_class}
# re_load_mod01 %>% class()
# re_load_mod02 %>% class()
# re_load_mod03 %>% class()
# re_load_mod04 %>% class()
# re_load_mod05 %>% class()
# re_load_mod06 %>% class()
# re_load_mod07 %>% class()
# re_load_mod08 %>% class()
# re_load_mod09 %>% class()
# re_load_mod10 %>% class()
```

```{r, show_reload_summary}
# re_load_mod01 %>% summary()
# re_load_mod02 %>% summary()
# re_load_mod03 %>% summary()
# re_load_mod04 %>% summary()
# re_load_mod05 %>% summary()
# re_load_mod06 %>% summary()
# re_load_mod07 %>% summary()
# re_load_mod08 %>% summary()
# re_load_mod09 %>% summary()
# re_load_mod10 %>% summary()
```

```{r, check_mod01_equal}
# all.equal( mod01, re_load_mod01 )
# all.equal( mod02, re_load_mod02 )
# all.equal( mod03, re_load_mod03 )
# all.equal( mod04, re_load_mod04 )
# all.equal( mod05, re_load_mod05 )
# all.equal( mod06, re_load_mod06 )
# all.equal( mod07, re_load_mod07 )
# all.equal( mod08, re_load_mod08 )
# all.equal( mod09, re_load_mod09 )
# all.equal( mod10, re_load_mod10 )
```

<!-- Which of the 10 models is the best? -->
<!-- • What performance metric did you use to make your selection? -->

```{r}
# extract_metrics <- function(mod_object, mod_name) {
#   broom::glance(mod_object) %>%
#     dplyr::mutate(model_name = mod_name)
# }
# 
# model_names <- c("mod01", "mod02", "mod03", "mod04", "mod05", "mod06", "mod07", "mod08", "mod09", "mod10")
# 
# glm_mle_results <- purrr::map2_dfr(
#   .x = list(mod01, mod02, mod03, mod04, mod05, mod06, mod07, mod08, mod09, mod10),
#   .y = model_names,
#   .f = extract_metrics
# )
# 
# glm_mle_results %>%
#   dplyr::select(model_name, AIC) %>%
#   tidyr::pivot_longer(c(AIC)) %>%
#   ggplot(mapping = aes(x = model_name, y = value)) +
#   geom_point(size = 5) +
#   theme_bw() +
#   labs(x = "Model Name", y = "AIC")
# 
# top_models <- glm_mle_results %>%
#   select(model_name, AIC) %>%
#   arrange(AIC) %>%
#   slice(1:3)  # Get top 3 models with the lowest AIC
# 
# glm_mle_results
# top_models
```

mod07 is considered the best, since it has lowest BIC value.

<!-- Visualize the coefficient summaries for your top 3 models -->

# ```{r}
# mod07 %>%
# coefplot::coefplot(intercept = FALSE) +
# theme_bw()
# mod09 %>% coef() %>% length()
# ```
# 
# ```{r}
# mod09 %>%
# coefplot::coefplot(intercept = FALSE) +
# theme_bw()
# mod07 %>% coef() %>% length()
# ```
# 
# ```{r}
# mod10 %>%
# coefplot::coefplot(intercept = FALSE) +
# theme_bw()
# mod10 %>% coef() %>% length()
# ```

<!-- How do the coefficient summaries compare between the top 3 models? -->
mod10 : There are a lot of coefficients, and some of them have quite big values, especially for interaction terms, which may indicate overfitting. When a model's complexity is too great for the volume of data, noise may be captured instead of the underlying relationship.
This model may be very complicated, with possible problems with multicollinearity and overfitting due to the magnitude of some of the coefficients.

mod06 : Compared to the first model, the coefficients are more closely clustered around zero, suggesting less extreme values.
Either the number of interaction terms is smaller than in the previous model, or the words that are included are simpler. This could indicate that the second model more effectively strikes a balance between complexity and fit.
There appears to be a potential linear association with the response variable without significant interaction effects, as indicated by the reduced coefficient values of the primary color coefficients (R, G, B) and the Hue.

mod09(Best Model) : This model may be easier to understand because it has fewer coefficients.
Compared to the second model, the coefficients are more dispersed, which could mean that some terms have a greater impact on the response variable.
Notable coefficients indicate that the model captures non-linear correlations for both the polynomial and linear variables.
Larger coefficients for terms like poly(B, 2) suggest a possibly significant quadratic link.

<!-- Which inputs seem important? -->
The coefficients that appear to have the largest values and hence may be considered important are:

mod09(Best Model) : 
poly(B, 2):poly(Hue, 2)
poly(R, 2):poly(G, 2)
These polynomial terms and their interactions suggest that there are significant non-linear relationships between these color model inputs and the response variable.

mod06 : 
The inputs R, G, B, and Hue appear as individual predictors, suggesting that each has a linear relationship with the response variable.

mod10 :
This model has an extensive number of coefficients, many of which have very large or very small values. However, due to the scale of the coefficients, it's challenging to discern the importance of specific inputs

<!-- Fit 2 Bayesian linear models – one must be the best model from iiA) and -->
<!-- the second must be another model you fit in iiA). -->
<!-- • State why you chose the second model. -->
<!-- • You may use the Laplace Approximation approach we used in lecture and -->
<!-- the homework assignments. -->

'mod09' is identified earlier as the best model based on the Bayesian Information Criterion (BIC) and 'mod04' is considered along with this.
'mod04' which includes all the main effects without any interactions or polynomial terms is chosen for the second model as it provides contrast in terms of complexity and variable interaction.

```{r}
# formula(mod07)
# formula(mod04)
# 
# ```
# ```{r}
# mod07 %>%
# coefplot::coefplot(intercept = FALSE) +
# theme_bw()
# mod04 %>%
# coefplot::coefplot(intercept = FALSE) +
# theme_bw()
```

Design matrices for both models

```{r}
Xmat_mod01 <- model.matrix( formula(mod01), data = dfii )
Xmat_mod02 <- model.matrix( formula(mod02), data = dfii )
Xmat_mod03 <- model.matrix( formula(mod03), data = dfii )
Xmat_mod04 <- model.matrix( formula(mod04), data = dfii )
# Xmat_mod05 <- model.matrix( formula(mod05), data = dfii )
# Xmat_mod06 <- model.matrix( formula(mod06), data = dfii )
# Xmat_mod07 <- model.matrix( formula(mod07), data = dfii )
# Xmat_mod08 <- model.matrix( formula(mod08), data = dfii )
# Xmat_mod09 <- model.matrix( formula(mod09), data = dfii )
# Xmat_mod10 <- model.matrix( formula(mod10), data = dfii )
# Xmat_mod07 <- model.matrix( formula(mod07), data = dfii )
# Xmat_mod04 <- model.matrix( formula(mod04), data = dfii )
```

```{r}
# purrr::map2_lgl(purrr::map(list(mod07, mod04),
# ~names(coef(.))),
# purrr::map(list(Xmat_mod07, Xmat_mod04),
# colnames),
# all.equal)
```

```{r}

info_mod01 <- list(
yobs = dfii$y,
design_matrix = Xmat_mod01,
mu_beta = 0,
tau_beta = 1,
sigma_rate = 1
)

info_mod02 <- list(
yobs = dfii$y,
design_matrix = Xmat_mod02,
mu_beta = 0,
tau_beta = 1,
sigma_rate = 1
)

info_mod03 <- list(
yobs = dfii$y,
design_matrix = Xmat_mod03,
mu_beta = 0,
tau_beta = 1,
sigma_rate = 1
)

info_mod04 <- list(
yobs = dfii$y,
design_matrix = Xmat_mod04,
mu_beta = 0,
tau_beta = 1,
sigma_rate = 1
)
# info_mod05 <- list(
# yobs = dfii$y,
# design_matrix = Xmat_mod05,
# mu_beta = 0,
# tau_beta = 1,
# sigma_rate = 1
# )
# 
# info_mod06 <- list(
# yobs = dfii$y,
# design_matrix = Xmat_mod06,
# mu_beta = 0,
# tau_beta = 1,
# sigma_rate = 1
# )
# info_mod07 <- list(
# yobs = dfii$y,
# design_matrix = Xmat_mod07,
# mu_beta = 0,
# tau_beta = 1,
# sigma_rate = 1
# )
# 
# info_mod08 <- list(
# yobs = dfii$y,
# design_matrix = Xmat_mod08,
# mu_beta = 0,
# tau_beta = 1,
# sigma_rate = 1
# )
# info_mod09 <- list(
# yobs = dfii$y,
# design_matrix = Xmat_mod09,
# mu_beta = 0,
# tau_beta = 1,
# sigma_rate = 1
# )
# 
# info_mod10 <- list(
# yobs = dfii$y,
# design_matrix = Xmat_mod10,
# mu_beta = 0,
# tau_beta = 1,
# sigma_rate = 1
# )
# info_mod07
# info_mod04
```

```{r}
lm_logpost <- function(unknowns, my_info) {
  # Specify the number of unknown beta parameters
  length_beta <- ncol(my_info$design_matrix)

  # Extract the beta parameters and varphi from the `unknowns` vector
  beta_v <- unknowns[1:length_beta]
  lik_varphi <- unknowns[length_beta + 1]

  # Safeguard against non-finite beta and varphi values
  if (!all(is.finite(beta_v)) || !is.finite(lik_varphi)) {
    return(-Inf)  # return a very low likelihood if non-finite values are encountered
  }

  # Back-transform from varphi to sigma, safeguarding against non-finite transformations
  lik_sigma <- exp(lik_varphi)
  if (!is.finite(lik_sigma)) {
    return(-Inf)
  }

  # Extract design matrix and calculate the linear predictor
  X <- my_info$design_matrix
  mu <- as.vector(X %*% as.matrix(beta_v))

  # Evaluate the log-likelihood
  log_lik <- sum(dnorm(x = my_info$yobs, mean = mu, sd = lik_sigma, log = TRUE))

  # Evaluate the log-prior
  log_prior_beta <- sum(dnorm(x = beta_v, mean = my_info$mu_beta, sd = my_info$tau_beta, log = TRUE))
  log_prior_sigma <- dexp(x = lik_sigma, rate = my_info$sigma_rate, log = TRUE)

  # Add the mean trend prior and noise prior together
  log_prior <- log_prior_beta + log_prior_sigma

  # Account for the transformation
  log_derive_adjust <- lik_varphi

  # Sum together and return
  log_lik + log_prior + log_derive_adjust
}

```

```{r}
my_laplace <- function(start_guess, logpost_func, ...)
{
# code adapted from the `LearnBayes`` function `laplace()`
fit <- optim(start_guess,
logpost_func,
gr = NULL,
...,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
mode <- fit$par
post_var_matrix <- -solve(fit$hessian)
p <- length(mode)
int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
# package all of the results into a list
list(mode = mode,
var_matrix = post_var_matrix,
log_evidence = int,
converge = ifelse(fit$convergence == 0,
"YES",
"NO"),
iter_counts = as.numeric(fit$counts[1]))
}
```




```{r}
laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod01)), lm_logpost, info_mod01)
laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod02)), lm_logpost, info_mod02)
laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod03)), lm_logpost, info_mod03)
laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod04)), lm_logpost, info_mod04)
# laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod05)), lm_logpost, info_mod05)
# laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod06)), lm_logpost, info_mod06)
# laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod07)), lm_logpost, info_mod07)
# laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod08)), lm_logpost, info_mod08)
# laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod09)), lm_logpost, info_mod09)
# laplace_quad <- my_laplace(rep(0, ncol(Xmat_mod10)), lm_logpost, info_mod10)
# laplace_A <- my_laplace(rep(0, ncol(Xmat_mod07)), logistic_logpost, info_mod07)
# laplace_B <- my_laplace(rep(0, ncol(Xmat_mod04)), logistic_logpost, info_mod04)
```






